---
title:  |
        | The Effect of Legislature Size on Public Spending:
        | A Meta-Analysis
date: \today
abstract: "In a seminal article, @weingast1981political argue that there is a positive relationship between legislature size and inefficiency in public expenditures. Their proposition is currently known as the \"law of $1/n$\" and has been widely debated in political science and public administration. However, recent studies have questioned the validity of the theory. In this letter, we conduct the first meta-analysis that assesses the generality of the \"law of $1/n$\". Based on a sample of 30 articles, we find no robust evidence suggesting that legislature size has either a positive or a negative effect on government budgets. Yet the aggregate results mask considerable heterogeneity. Our findings provide moderate support for the \"law of $1/n$\" in unicameral legislatures and in upper houses, but they also indicate that papers using panel/fixed-effects models or regression discontinuity designs report negative public spending estimates. We find only limited evidence that electoral systems impact public spending, which suggests that proportional representation systems may not be more prone to overspending than majoritarian ones."
abstractspacing: double
keywords: distributive politics; law of $1/n$; legislature size; meta-analysis; public spending
jelcodes: H21; H23; H50; H61
fontsize: 11pt
margin: 2cm
urlcolor: darkblue
linkcolor: Mahogany
citecolor: Mahogany
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    keep_tex: no
    toc: no
    toc_depth: 3
    template: article-template.latex
    md_extensions: +raw_attribute
---

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Knitr options
knitr::opts_chunk$set(fig.pos = "H") # holds figure position
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Clean up
rm(list = ls())

## Starting
set.seed(732578) # From random.org

# Needed packages
pkgs <- c("tidyverse", "meta", "metafor",
          "readxl", "data.table",
          "knitr", "gridGraphics", "gridExtra",
          "ggpubr", "kableExtra", "magick")

# Install if not already installed
installIfNot <- function(x) {
  if (x %in% rownames(installed.packages()) == FALSE)
    install.packages(x, dependencies = T,
					 repos = "http://cran.us.r-project.org")
}
lapply(pkgs, installIfNot)

# Load packages
lapply(pkgs, require, character.only = T)
devtools::install_github("isubirana/compareGroups")
library("compareGroups")

# Load datasets
load("../dataset/dataCoefs.RData")

# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect",
                            "Prediction Interval"),
                lower = c(mod$lower.random,
                          mod$lower.predict),
                upper = c(mod$upper.random,
                          mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2, TE),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(group~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}

# Build forest plot for heterogeneous analysis
# Build plot function for forest plots
build_forest_het <- function(mod, capt, lsize = 22, ttl = NULL, hetvar = NULL) {
  mod <- update(mod, byvar = hetvar, print.byvar = F)
  
  # Build dataset for plot
  mod2 <- tibble(
    byvar = mod$byvar,
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    arrange(byvar)
  auxmod <- tibble()
  for (i in rev(mod$bylevs)){
    auxmod <- rbind(auxmod, tibble(byvar = i,
                    TE = NA,
                    seTE = NA,
                    studlab = toupper(i),
                    lower = NA,
                    upper = NA,
                    group = "B"))
    auxmod <- rbind(auxmod, 
                    filter(mod2, byvar==i) %>% 
                      arrange(desc(TE)))
    auxmod <- rbind(auxmod, tibble(
      byvar = i,
      TE = mod$TE.random.w[which(mod$bylevs==i)],
      seTE = mod$seTE.random.w[which(mod$bylevs==i)],
      studlab = 'Subgroup Effect',
      lower = mod$lower.random.w[which(mod$bylevs==i)],
      upper = mod$upper.random.w[which(mod$bylevs==i)],
      group = "B"))
  }
  auxmod <- rbind(auxmod, tibble(
    byvar = NA,
    TE = c(mod$TE.random, NA),
    seTE = c(mod$seTE.random, NA),
    studlab = c("Overall Effect", "Prediction Interval"),
    lower = c(mod$lower.random, mod$lower.predict),
    upper = c(mod$upper.random, mod$upper.predict),
    group = "B"))
  mod2 <- data.frame(auxmod)
  mod2$byvar <- toupper(mod2$byvar)
  TEaux <- mod2$TE
  TEaux[mod2$studlab== 'Subgroup Effect'] = TEaux[mod2$studlab== 'Subgroup Effect'] - 100
  
  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))
  
  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab, TEaux),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(byvar~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}

export2md2<-function(x, which.table="descr", nmax=TRUE, header.labels=c(),
                    caption=NULL, format="html", width=Inf,
                    strip=FALSE, first.strip=FALSE, background="#D2D2D2",
                    size=NULL, landscape=FALSE,
                    header.background=NULL, header.color=NULL,
                    position="center", ...){

  trim <- function(x){
    x <- gsub("^[ ]+","",x)
    x <- gsub("[ ]+$","",x)
    x
  }

  prepare <- function (x, nmax, header.labels)
    {

        # x <- tab[1:3]
        # nmax <- TRUE
        # header.labels <- c()
        # names(attributes(x))

        show.all <- attr(x, "show.all")
        show.descr <- attr(x, "show.descr")
        groups <- attr(x, "groups")
        ny <- attr(x, "ny")
        all.last <- attr(x, "all.last")

        varnames <- attr(x, "varnames")
        nr <- attr(x, "nr")
        desc <- x$desc
        avail <- x$avail
        nmax.pos <- attr(x, "nmax.pos")
        nmax.avail.pos <- NULL
        if (length(nmax.pos[[1]]) == 0 & length(nmax.pos[[2]]) == 0) nmax.avail.pos <- integer(0)
        if (length(nmax.pos[[1]]) == 0 & length(nmax.pos[[2]]) > 0) nmax.avail.pos <- nmax.pos[[2]] + 1
        if (length(nmax.pos[[1]]) > 0 & length(nmax.pos[[2]]) == 0) nmax.avail.pos <- 1
        if (length(nmax.pos[[1]]) > 0 & length(nmax.pos[[2]]) > 0) nmax.avail.pos <- c(1, nmax.pos[[2]])
        if (length(nmax.avail.pos) > 0 && nmax) {
            Nmax <- apply(avail[, nmax.avail.pos, drop = FALSE],2, function(x) max(as.double(x)))
        } else {
            Nmax <- NULL
            nmax <- FALSE
        }

        dd.pos <- attr(x, "dd.pos")
        j <- 1
        table1 <- NULL
        if (!is.null(attr(x, "caption")))
            cc <- character(0)
        for (i in 1:length(varnames)) {
            if (nr[i] == 1) {
                t.i <- desc[j, , drop = FALSE]
            } else {
                t.i <- rbind(rep(NA, ncol(desc)), desc[j:(j + nr[i] -
                                                              1), , drop = FALSE])
                rownames(t.i)[1] <- paste(varnames[i], ":", sep = "")
                rownames(t.i)[-1] <- sub(varnames[i], "", rownames(t.i)[-1], fixed = TRUE)
                rownames(t.i)[-1] <- sub(": ", "    ", rownames(t.i)[-1])
                if (length(dd.pos) < ncol(t.i)) {
                    t.i[1, -dd.pos] <- t.i[2, -dd.pos]
                    t.i[2, -dd.pos] <- NA
                }
            }
            table1 <- rbind(table1, t.i)
            j <- j + nr[i]
            if (!is.null(attr(x, "caption"))) {
                if (attr(x, "caption")[[i]] == "")
                    cc <- c(cc, rep("", NROW(t.i)))
                else cc <- c(cc, attr(x, "caption")[[i]], rep("",
                                                              NROW(t.i) - 1))
            }
        }
        if (ncol(table1) == 0) table1 <- table1[-1, ]
        if (nmax) table1 <- rbind(colnames(table1), c(paste("N=", Nmax, sep = ""), rep("", ncol(table1) - length(Nmax))), table1) else table1 <- rbind(colnames(table1), table1)
        table1 <- ifelse(is.na(table1), "", table1)
        if (length(header.labels)==6 && is.null(names(header.labels))){
            names(header.labels)<-c("all","p.overall","p.trend","ratio","p.ratio","N")
        }
        if ("all"%in%names(header.labels)){
            ww.all<-grep("^\\[ALL\\]",trim(table1[1,]))
            if (length(ww.all)>0){
                ww.all<-ww.all[1]
                table1[1,ww.all]<-header.labels["all"]
            }
        }
        if ("p.overall"%in%names(header.labels)){
            ww.p.overall<-which(table1[1,]=="p.overall")
            if (length(ww.p.overall)>0){
                ww.p.overall<-rev(ww.p.overall)[1]
                table1[1,ww.p.overall]<-header.labels["p.overall"]
            }
        }
        if ("p.trend"%in%names(header.labels)){
            ww.p.trend<-which(table1[1,]=="p.trend")
            if (length(ww.p.trend)>0){
                ww.p.trend<-rev(ww.p.trend)[1]
                table1[1,ww.p.trend]<-header.labels["p.trend"]
            }
        }
        if ("ratio"%in%names(header.labels)){
            ww.ratio<-which(table1[1,]%in%c("OR","HR"))
            if (length(ww.ratio)>0){
                ww.ratio<-rev(ww.ratio)[1]
                table1[1,ww.ratio]<-header.labels["ratio"]
            }
        }
        if ("p.ratio"%in%names(header.labels)){
            ww.p.ratio<-which(table1[1,]=="p.ratio")
            if (length(ww.p.ratio)>0){
                ww.p.ratio<-rev(ww.p.ratio)[1]
                table1[1,ww.p.ratio]<-header.labels["p.ratio"]
            }
        }
        if ("N"%in%names(header.labels)){
            ww.N<-which(table1[1,]=="N")
            if (length(ww.N)>0){
                ww.N<-rev(ww.N)[1]
                table1[1,ww.N]<-header.labels["N"]
            }
        }
        table1 <- apply(table1, 2, format, justify = "centre")
        colnames(table1) <- rep("", ncol(table1))



        table2 <- x[[2]]
        table2 <- as.matrix(table2)
        table2 <- ifelse(is.na(table2), "", table2)
        table2 <- rbind(colnames(table2), table2)
        table2 <- apply(table2, 2, format, justify = "centre")
        colnames(table2) <- rep("", ncol(table2))

        # rearrange table 1 and table 2 by putting all column after descriptives by groups.
        if (all.last & show.all & show.descr & groups){
            table1[,1:(ny+1)] <- table1[,c(2:(ny+1),1)]
        }
        if (all.last){
            table2[,1:(ny+1)] <- table2[,c(2:(ny+1),1)]
        }

        # out
        out <- list(table1 = table1, table2 = table2)
        if (!is.null(attr(x, "caption"))) attr(out, "cc") <- cc
        attr(out, "nmax") <- nmax
        nr <- ifelse(nr>1, nr+1, nr)
        nr <- cbind(nr, rep(0:1, length(nr))[1:length(nr)])
        nr <- unlist(apply(nr, 1, function(x) rep(x[2],x[1])))
        attr(out, "nr") <- nr
        out

    }

  # compiled.format <- try(rmarkdown::all_output_formats(knitr::current_input())[1],silent=TRUE)
  #
  # if (inherits(compiled.format, "try-error") || is.null(compiled.format)){
  #   warning("you are using export2md out of Rmarkdown context...")
  # } else {
  #   if (compiled.format%in%c("html_document","ioslides_presentation","slidy_presentation")) format <- "html"
  #   if (compiled.format%in%c("pdf_document","beamer_presentation")) format <- "latex"
  #   if (compiled.format=="word_document") format <- "markdown"
  # }

  if (missing(format)){
    format <- NA
    if (!interactive()){ # execute inside Rmarkdown
      if (knitr::is_html_output()) format="html"
      if (knitr::is_latex_output()) format="latex"
      if (!knitr::is_html_output() & !knitr::is_latex_output()) format="markdown"
      if (is.na(format)){
        warning("Unable to identify format -> HTML assigned.")
        format <- "html"
      }
    } else {# execute inside Rmarkdown
      warning("You are calling export2md outside Rmarkdown without specifying format -> html format is assigned")
      format <- "html"
    }
  }

  extras <- list(...)
  if (!inherits(x, "createTable"))
    stop("x must be of class 'createTable'")
  if (inherits(x, "cbind.createTable"))
    stop("x cannot be of class 'cbind.createTable'")
  ww <- charmatch(which.table, c("descr", "avail"))
  if (is.na(ww))
    stop(" argument 'which.table' must be either 'descr' or 'avail'")

  if (attr(x,"groups")){
    y.name.label<-attr(x,"yname")
  }

  if (!is.null(caption)){
    if (!is.character(caption))
      stop(" argument 'caption' must be a character'")
  } else {
    if (ww==1){
      if (attr(x,"groups"))
        if (inherits(x,"missingTable"))
          caption<-paste("Missingness table by groups of `",y.name.label,"'",sep="")
      else
        caption<-paste("Summary descriptives table by groups of `",y.name.label,"'",sep="")
      else
        if (inherits(x,"missingTable"))
          caption<-"Missingess table"
        else
          caption<-"Summary descriptives table"
    }
    if (ww==2){
      if (attr(x,"groups"))
        caption<-paste("Available data by groups of `",y.name.label,"'",sep="")
      else
        caption<-"Available data"
    }
  }
  pp <- compareGroups:::prepare(x, nmax = nmax, header.labels)
  #pp <- prepare(x, nmax = nmax, header.labels)
  cc <- unlist(attr(pp, "cc"))
  if (ww %in% c(1)) {
    table1 <- pp[[1]]
    ii <- ifelse(rownames(table1)[2] == "", 2, 1)
    table1 <- cbind(rownames(table1), table1)
    align <- c("l", rep("c", ncol(table1)))
    table1[1, 1] <- " "
    colnames(table1) <- table1[1, ]
    colnames(table1)[-1] <- trim(colnames(table1)[-1])
    table1 <- table1[-1, , drop = FALSE]
    table1[,2:ncol(table1)] <- apply(table1[,-1,drop=FALSE],2,trim)
    #table1 <- table1[-2]
    #names(table1)[1] <- 'Extended Sample'
    # N in the second row
    table1 <- table1[,-3]
    colnames(table1)[2] <- 'Extended Sample'
    table1 <- table1[,c(1,3,2)]
    n.exists <- nrow(table1) > 1 && length(grep("^N=", trim(table1[1, 2])))
    if (format=="latex" & strip)
      table1[((1+n.exists):nrow(table1)),ncol(table1)] <- ifelse(table1[((1+n.exists):nrow(table1)),ncol(table1)]=="", "\\vphantom{}", table1[((1+n.exists):nrow(table1)),ncol(table1)])
    if (format=="latex") caption <- gsub("%","\\\\%",caption)
    ans <- knitr::kable(table1, align = align, row.names = FALSE, caption=caption[1], format=format,
                        booktabs=format=="latex", longtable=TRUE, linesep="", ...)
    ans <- add_indent(ans, grep("^ ",table1[,1]))
    if (width!=Inf) ans <- column_spec(ans, 1, width = width)
    # groups
    if (!is.null(cc)){
      for (cci in 1:length(cc)){
        if (cc[cci]!=""){
          group.label <- cc[cci]
          inici <- 0
          final <- 0
        } else {
          if (cc[cci-1]!="")
            group.begin <- cci-1
          if (cci==length(cc) || cc[cci+1]!=""){
            group.end <- cci
            ans <- group_rows(ans, group.label, group.begin+n.exists, group.end+n.exists)
          }
        }
      }
    }
    if (strip){
      nr <- attr(pp, "nr")
      ans <- row_spec(ans, which(nr==!first.strip)+n.exists, background = background)
    }
    if (n.exists){
      ans <- row_spec(ans, 1, hline_after=TRUE)
    }

    if (landscape) ans <- landscape(ans)
    if (format=="latex"){
      ans <- kable_styling(ans, latex_options = c("repeat_header"), font_size=size, position=position)
      #if (n.exists) ans <- gsub("\\\\midrule", "", ans) # remove lines after N
      if (n.exists) ans <- gsub("\\\\midrule\n\\\\endfirsthead", "\\\\endfirsthead", ans) # remove lines after N
      if (strip) ans <- gsub("\\textbackslash{}vphantom\\{\\}", "\\vphantom{}", ans, fixed=TRUE)
    }
    if (format=="html"){
      ans <- kable_styling(ans, bootstrap_options=c(if (!strip) "striped" else NULL, "condensed"), full_width=FALSE, font_size=size, position=position)
      ans <- row_spec(ans, 0, background=header.background, color=header.color)
      ans <- row_spec(ans, if (sum(unlist(attr(x, "nmax.pos")))>0) 1 else 0, italic=sum(unlist(attr(x, "nmax.pos")))>0, extra_css = "border-bottom: 1px solid grey")
    }
    return(ans)
  }
  if (ww %in% c(2)){
    # table2 <- compareGroups:::prepare(x, nmax = nmax, c())[[2]]
    table2 <- prepare(x, nmax = nmax, c())[[2]]
    table2 <- cbind(rownames(table2), table2)
    if (!is.null(attr(x, "caption"))) {
      cc <- unlist(attr(x, "caption"))
      table2[, 1] <- paste("    ", table2[, 1])
    }
    table2[1, 1] <- " "
    align <- c("l", rep("c", ncol(table2)))
    colnames(table2)[-1] <- trim(table2[1, -1])
    table2 <- table2[-1, ,drop=FALSE]
    ans <- knitr::kable(table2, align = align, row.names = FALSE, caption=caption[1], format=format, booktabs=format=="latex", longtable=TRUE, ...)
    # ans <- knitr::kable(table2, align = align, row.names = FALSE, caption=caption[1], format=format, booktabs=format=="latex")
    # groups
    if (!is.null(cc)){
      for (cci in 1:length(cc)){
        if (cc[cci]!=""){
          group.label <- cc[cci]
          inici <- 0
          final <- 0
        } else {
          if (cc[cci-1]!="")
            group.begin <- cci-1
          if (cci==length(cc) || cc[cci+1]!=""){
            group.end <- cci
            ans <- group_rows(ans, group.label, group.begin, group.end)
          }
        }
      }
    }
    ans <- add_indent(ans, integer())
    if (strip) ans <- row_spec(ans, which(rep(0:1, nrow(table2))[1:nrow(table2)]==!first.strip), background = background)
    if (width!=Inf) ans <- column_spec(ans, 1, width = width)
    if (landscape) ans <- landscape(ans)
    if (format=="latex"){
      ans <- kable_styling(ans, latex_options = c("repeat_header"), font_size = size, position=position)
    }
    if (format=="html"){
      ans <- kable_styling(ans, bootstrap_options=c(if (!strip) "striped" else NULL, "condensed"), full_width = FALSE, font_size = size, position=position)
      ans <- row_spec(ans, 0, background=header.background, color=header.color)
      ans <- row_spec(ans, 0, italic=FALSE, extra_css = "border-bottom: 1px solid grey")
    }

    return(ans)
  }
}
```

\newpage

# Introduction
\label{sec:intro}

Over the past decades, a large literature has examined the relationship between
legislature size and public expenditure. @weingast1981political provided the
general framework to analyse distributive politics. The authors argue that the
larger the number of legislative districts ($n$), the smaller the share of tax
burden each one will bear ($1/n$), thus legislators have an incentive to
overspend in their districts and transfer the costs to the entire polity. Early
studies that empirically tested the "law of $1/n$", as the theory is currently
known, indeed found a positive correlation between the number of legislature
seats and different measures of government spending, although these first
results were mainly based on US state legislatures and the effect was often
limited to one house [e.g., @baqir2002districting; @gilligan1995deviations;
@gilligan2001fiscal]. 

Later research, however, has questioned the validity of the "law of $1/n$".
@primo2008distributive affirm that, due to spatial spillovers, a collection of
small districts can supply public goods more efficiently than the central
government. The authors conclude that a "reverse law of $1/n$" may hold,
wherein a higher number of legislators in small constituencies decrease the
overall public spending. Similarly, @primo2006stop and @chen2007law find that
lower and upper chambers may have mixed effects on government spending, while
@petterssonlidbom2012size argues that the impact of larger chamber sizes is
negative when using data from Finland and Sweden.

Since many empirical tests of the "law of $1/n$" have produced conflicting
results, scholars have expanded this research agenda and closely investigated
how institutional factors condition the original formulation of the theory. For
instance, authors such as @crowley2019law and @pecorino2018supermajority
accurately point out that collective action problems have been overlooked in
the literature, and recent findings indicate that bicameralism
[@maldonado2013legislatures], intergovernmental competition
[@crowley2015local], redistricting [@lee2018court], and party ideology
[@bjedov2014impact] strongly influence the relationship between seats and
spending. Moreover, the literature has increasingly applied causal inference
methods to estimate the effect of the "law of $1/n$", and in contrast to
previous studies using panel data, regression discontinuity designs generally
indicate that more legislators decrease public expenditures
[@debenedetto2018effect; @hohmann2017effect; @lewis2019legislature;
@petterssonlidbom2012size]. In this respect, scholars have long been aware of
the theoretical and empirical limitations of the "law of $1/n$", and the
proliferation of new studies reflect a conscious attempt to assess the
robustness of the theory.

In this letter, we conduct the first meta-analysis that tests the generality of
the "law of $1/n$". We select `r length(unique(dat$id))` articles that use
quantitative methods to evaluate the impact of legislature size over government
spending across several dimensions. Our study sample mirrors the diversity of
the literature. We found articles that present a positive association between
the number of legislators and public expenditures, others suggesting that such
relationship is negative, and yet others that claim that there is no
correlation between them. Given the volume and the disparity of the studies, we
employ meta-analysis to summarise the results. Meta-analysis provides a
rigorous approach to combine heterogeneous outcomes into a single estimation,
and it allows scholars to gain valuable insights from the aggregated data
[@cooper2019handbook; @hedges1985statistical]. Meta-analysis can also identify
potential sources of study variability, enabling researchers to assess threats
to external validity and direct future efforts into more promising areas of
academic inquiry [@doucouliagos2008democracy]. Research synthesis methods have
been successfully applied in medicine and psychology since the 1970s
[@glass2015meta], and our work contributes to the burgeoning literature that
uses meta-analytic methods to understand challenging questions in political
science [@costa2017responsive; @doucouliagos2008democracy; @green2013field;
@lau2007effects; @schwarz2020supporting].

We run meta-regressions to further evaluate the relationship between
legislature size and government expenditures. In those analyses, we measure the
effect of five moderators that capture different sources of heterogeneity in
the literature. In our Supplementary Materials, we also include binomial
tests to assess whether the proportions of positive and negative coefficients
are statistically different from each other, as well as funnel plots to test
for publication bias in existing research on the "law of $1/n$"
[@easterbrook1991publication; @gerber2001testing].

Aggregate results indicate that legislature size has no significant impact on
public spending. All of our main meta-analysis estimates show that the overall
effect is not statistically different from zero, thus confirming the
conflicting findings reported by the literature. However, when we look only at
articles that employ regression discontinuity designs (RDDs), we see that all
four papers included in our sample suggest that a higher number of legislators
leads to lower public spending [@debenedetto2018effect; @hohmann2017effect;
@lewis2019legislature; @petterssonlidbom2012size]. In this regard, it is
possible that methodological choices partially explain the divergent results
observed in the literature, as articles that use RDDs consistently point to the
same direction. One limitation of this finding is that these studies only test
the impact of lower house size and its natural logarithm on the natural
logarithm of expenditure per capita, thus it remains unclear whether the
results hold with other variables.

The meta-regressions provide additional evidence that our study sample is
highly heterogeneous and that effect sizes differ substantially according to
study specifications. When using an extended sample of `r dim(fulldat)[1]`
coefficients, we find that unicameralism is associated with higher public
spending, as predicted by the "law of $1/n$". Moreover, one of our
meta-regressions indicates that larger upper chambers spend more in terms of
per capita expenditure than lower chambers, a result that also appears in the
binomial tests. Overall, non-majoritarian voting systems seem to decrease
government spending, following the idea that the $1/n$ effect grows weaker as
the empirical cases distance from the original definition of the law. Finally,
meta-regression results confirm that regression discontinuity designs reduce
public spending estimates.

# Data and Methods

We compiled our study sample in three search rounds. In the first round, we
gathered data from three large academic databases (Scopus, Microsoft Academic,
and Google Scholar) and looked for studies that were written in English and
cited \citet{weingast1981political}, as it is the foundational work in the
literature on the "law of $1/n$". To ensure that our sample was comparable, we
only selected papers that used quantitative methods to analyse
data\footnote{Since meta-analysis requires a single estimate per observation,
we excluded articles that use interaction terms or quadratic specifications of
our selected variables. Please refer to Section C in the Supplementary Material
for a detailed description of the selection procedure. We also included two
PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses)
flow diagrammes \citep{liberati2009prisma} showing the number of resulting
papers after each review step.}. After this stage, we identified six
measurements that the literature often employs to quantify government
expenditure and legislature size. For government expenditure, our study sample
uses (i) public expenditure as a share of GDP; (ii) public expenditure per
capita; and (iii) the natural logarithm of public expenditure per capita as its
main variables of interest. In regards to legislature size, the variables are
(i) lower chamber size; (ii) natural logarithm of lower chamber size; and (iii)
upper chamber size\footnote{There are a few important nuances concerning coding
of these variables. Unicameralism, for example, is captured both by lower
chamber size ($n = 7$) and by log lower chamber size ($n = 5$). Since much of
the literature estimates how institutional designs affect this relationship,
ours and many other articles use both lower and upper chamber sizes as main
explanatory variables. We did not find any article that used the natural
logarithm of upper chamber size in their models.}. 

In the second round, we did not require articles to cite @weingast1981political
and used a keyword-based query on Google Scholar to broaden the scope of the
first search. The search string contained terms strongly associated with the
literature on the "law of $1/n$" and it was as follows: `("upper chamber size" OR
"lower chamber size" OR "council size" OR "parliament size" OR "legislature
size" OR "number of legislators" OR "legislative size") AND ("spending" OR
"expenditure" OR "government size")`. We again restricted the search to
articles written in English which employed quantitative methods. This search
added two new results to our sample [@coate2011government;
@debenedetto2018effect], but neither of them included variables beyond the six
measures we had previously identified. In the third search round, we looked
into the personal webpages of every author whom we had already included in our
sample. The purpose of this manual search was to assess whether there was any
working paper or unpublished manuscript that we had missed in the two former
queries. We did not find any new article that satisfied the inclusion criteria
in this search. The full list of excluded records is available for online
consultation in the replication materials. Combined, the three searches
produced a dataset of `r length(unique(dat$id))` studies as of the
10\textsuperscript{th} of March 2021. Table \ref{tab:papers} contains the full
list of articles we analyse in this paper.

\newpage

\scriptsize
\begin{longtable}{>{\raggedright\arraybackslash}p{3.9cm}>{\centering\arraybackslash}p{1.5cm}>{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{2.3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{1.1cm}}
\caption{Papers included in the meta-analysis, ordered by year of appearance}\\
\toprule
\raggedright Author(s) & \centering Journal & \centering Country & \centering Dependent Variable & \centering Method & \centering Institutional Design & \centering Electoral System
\tabularnewline
\midrule
\endhead
```{r papers, echo = FALSE, results = 'asis', cache = T}
build_nams <- function(x) {
  x_ <- unlist(strsplit(as.character(x), ' & ', fixed = T, useBytes = T))
  if(length(x_) == 1) return(x_)
  else {
    aux <- x_[1]
      for (i in 2:length(x_))
        if (i == length(x_)){
          aux <- paste(aux, ' \\& \\\\ ', x_[i], sep = '')
        } else {
          aux <- paste(aux, ',\\\\ ', x_[i], sep = '')
        }
  }
  return(paste('\\begin{tabular}[t]{@{}l@{}}', aux,'\\end{tabular}', 
                   sep = ''))
}
aux <- dat %>%
  select(authoryear, journalCode, locationISO, depvar2, method, instdesign, elecsys3, year) %>%
  unique() %>%
  arrange(year, depvar2)
aux2 <- aux %>%
  mutate(depvar2 = 'aux') %>%
  unique()
for(i in 1:dim(aux)[1]) {
  if(aux2$depvar2[aux2$authoryear == aux$authoryear[i]] == 'aux') {
    aux2$depvar2[aux2$authoryear == aux$authoryear[i]] = aux$depvar2[i]
  } else {
    aux2$depvar2[aux2$authoryear == aux$authoryear[i]] = paste(
      aux2$depvar2[aux2$authoryear == aux$authoryear[i]],
      aux$depvar2[i], sep = ', ')
  }
}
aux <- aux2
for (i in 1:dim(aux)[1]) {
  cat(paste(build_nams(aux$authoryear[i]), ' & ', aux$journalCode[i], ' & ',
      aux$locationISO[i], ' & ', aux$depvar2[i], ' & ', 
      aux$method[i], ' & ', aux$instdesign[i], ' & ', 
      aux$elecsys3[i], ' \\\\ [0.5ex]', sep = ''), '\n')
}
```
\bottomrule
\label{tab:papers}
\begin{minipage}{\textwidth}
\renewcommand{\footnoterule}{}
\vspace{-0.5cm}
\scriptsize
\footnotetext{\scriptsize \textbf{Journal:} Unpub $=$ Unpublished, JPE $=$ Journal of Political
Economy, EJPE $=$ European Journal of Political Economy, PC $=$ Public Choice,
JPubE $=$ Journal of Public Economics, JPriE $=$ Journal of Private Enterprise,
APSR $=$ American Political Science Review, SEJ $=$ Southern Economic Journal,
UAR $=$ Urban Affairs Review, SCID $=$ Studies in Comparative International
Development, SSQ $=$ Social Science Quarterly, SPPQ $=$ State Politics and Policy
Quarterly, CPS $=$ Comparative Political Studies, RivPE $=$ Rivista di Politica
Economica, E\&P $=$ Economics and Politics, NTJ $=$ National Tax Journal.}
\footnotetext{\scriptsize \textbf{Country:} Country codes follow the ISO 3166-1 alpha-3
international standard.} 
\footnotetext{\scriptsize \textbf{Dependent Variable:} ExpPC $=$ Per capita expenditure,
logExpPC $=$ Natural logarithm of per capita expenditure, PCTGDP $=$ Expenditure as
a percentage of GDP.}
\footnotetext{\scriptsize \textbf{Method:} OLS $=$ Ordinary least squares, IV $=$ Instrumental
variables, Panel $=$ Panel data/fixed effects, RDD $=$ Regression discontinuity
design.}
\footnotetext{\scriptsize \textbf{Electoral System:} M $=$ Majoritarian, NM $=$ Non-majoritarian (mixed or proportional
representation).} 
\end{minipage} 
\end{longtable}
\normalsize

Our study sample reflects the development of the literature. Although the "law
of $1/n$" was first formulated in 1981, the empirical assessment of the theory
only started a few years later, as dates of publishing range from `r min(dat$year)`
to `r max(dat$year)`. Most studies focus on the United States (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='USA')])`), but our sample also contains
papers on Australia (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='AUS')])`), Brazil (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='BRA')])`), Germany (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='DEU')])`), Indonesia (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='IDN')])`), Italy (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='ITA')])`), and
Switzerland (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='CHE')])`). Seven articles use cross-national data and analyse from 2 to 110
countries. Early studies used OLS and panel data methods to estimate the
results, while studies from 2005 onward have also applied causal inference
models such as instrumental variables and regression discontinuity designs to
test the relationship between house size and public spending.

Regarding the dependent variables included in the sample, `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='ExpPC')])` studies employ
public expenditure per capita, `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='logExpPC')])` papers use its natural logarithm, and `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='PCTGDP')])` of them
analyse the impact of legislature size on public expenditures as a percentage of
GDP. This indicates that the area has refined the original definition of the "law of $1/n$"
and tested the impact of larger legislatures on different measures of government
spending. Our independent variables are lower chamber size 
(`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='N')])`), the natural
logarithm of lower chamber size (`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='logN')])`), and upper chamber size (`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='K')])`). 
These variables formed a $3 \times 3$ table, yet not all combinations were
available in the data. We found no studies that correlate public expenditure
per capita with either upper chamber size or the natural logarithm of lower
house size. Thus, our meta-analysis contains seven of the nine possible
variable combinations.

We also coded five moderators that may help us understand the heterogeneity in
the reported results. We included them in our meta-regressions alongside an
indicator for the type of independent variable used in the original study. The
additional moderators are: 1) publication year; 2) paper publication in an
academic journal; 3) estimation method; 4) institutional design; 5) electoral
system. Since the literature on the "law of $1/n$" is notably diverse, we
added only moderators that either refer to important theoretical questions,
such as the effect of the electoral system on public spending, or to essential
characteristics of the publications themselves. Although more moderators exist
in the literature (e.g., data aggregation level), they do not appear as often
as necessary for their inclusion in the meta-regressions. Table
\ref{tab:descriptive} shows the descriptive statistics of the moderator
variables. 

\vspace{.5cm}

\footnotesize
```{r descriptive, warning=F, message=F, echo = FALSE, cache=TRUE, results='asis'}
fulldat$usemeta2 <- factor(fulldat$usemeta)
levels(fulldat$usemeta2) <- c("Other coefficients", "Main Sample")
aux <- select(fulldat, usemeta2, indepvar2, elecsys2, method,
              year, published, instdesign) %>%
  rename(`Independent Variables` = indepvar2,
         `Year`                  = year,
         `Published work`        = published,
         `Estimation method`     = method,
         `Institutional Design`  = instdesign,
         `Electoral system`      = elecsys2)
aux$`Independent Variables` <- recode(aux$`Independent Variables`,
                                      `N` = "Lower Chamber Size",
                                      `K` = "Upper Chamber Size",
                                      `logN` = "Log of Lower Chamber Size")
aux$`Electoral system` <- recode(aux$`Electoral system`,
                                 `Non-Maj` = "Non-Majoritarian",
                                 `Maj` = "Majoritarian")
aux <- select(aux, usemeta2, `Independent Variables`, Year, `Published work`, `Estimation method`, `Institutional Design`, `Electoral system`)

aux3 <- descrTable(~.-usemeta2, 
                   aux, y = aux$usemeta2,
                   show.p.overall = F, 
                   show.all = T)
export2md2(aux3, 
           caption = "Descriptive Statistics of Moderators", 
           format  = "latex")

```
\normalsize

A key methodological issue we had to address concerns the potential violation
of an important assumption in a meta-analysis, that of effect size independence
[@cheung2014modeling; @cheung2019guide; @veroniki2016methods]. In our study
sample, authors frequently use the same datasets, and almost all papers fit more
than one regression with similar variables, what suggests that the assumption
above does not hold. We use two procedures to tackle this problem. First, we
created two sets of study coefficients to reduce the impact of
multicollinearity in our estimations. The first group includes only the most
rigorous models from each paper, that is, those estimated with the largest $n$,
most control variables, and fixed effects if the authors added them. If the
article employed a regression discontinuity design, we chose the coefficient
from the optimal bandwidth or from the intermediate one. This sample
encompasses `r dim(dat)[1]` estimates, as 
`r as.numeric(sum(table(table(dat$id))[-1]))` articles analysed two dependent or
independent variables of interest\footnote{The papers that used more than one
dependent or independent variable of interest are \citet{bjedov2014impact,
bradbury2001legislative, chen2007law, crowley2019law, erler2007termlimits,
gilligan2001fiscal, lee2015supermajority, lee2016supermajority, lee2018court,
maldonado2013legislatures, primo2006stop, ricciuti2003trading,
ricciuti2004legislatures}.}. Our second sample, in contrast, contains all the
`r dim(fulldat)[1]` effect sizes reported in the `r length(unique(dat$id))`
papers. Here we focus on the results for our restricted sample as we consider
them more robust, but the findings are nearly identical when we use the
extended set.

Our second procedure consists of employing multilevel random effect models
[@cheung2014modeling; @matthes2019meta] in all of our estimations. We add two
extra levels to the regular meta-analysis, one including a unique publication
ID for each paper, and another building a common index for papers that share
the same data specifications. By adding these two levels, we account for
within- and between-study variation, thus removing these sources of effect size
dependency and improving the accuracy of the results. More information about
the multilevel models can be found in Section H.1 of the Supplementary
Material. 

We use Hedges' $g$ to calculate effect sizes in our meta-analysis
[@hedges1981distribution]. While there are other methods to standardise
coefficients in meta-analytic studies, Hedges' $g$ corrects for upward bias in
small sample sizes and is considered more robust than measures such as Cohen's
$d$ [@lakens2013calculating]. We estimate the Standardised Mean Difference
(SMD), which represents the effect size in each study relative to the
variability observed in that study, by extracting the coefficients and the
standard errors from all articles included in our sample and converting them to
Hedges' $g$. In cases where authors did not report the standard errors for
their estimates, we computed them using the t-statistic presented in the
original tables. 

# Results

The "law of $1/n$" states that more legislators increase government
expenditure. In this paper, we employ two methods to test the empirical
validity of that relationship.\footnote{We also run preliminary binomial Z
tests in section G of the Supplementary Materials.} First, we fit nine
multilevel meta-analyses using the `meta` [@balduzzi2019perform] and the
`dmetar` [@dmetar2019] packages for the `R` statistical language [@rstats2019].
Then, we run four sets of meta-regressions to measure the effects of a group of
moderators on the effect sizes of our study sample. To recapitulate, our
independent variables of interest are lower chamber size, the natural logarithm
of lower chamber size, and upper chamber size. The dependent variables are
public expenditure per capita, the natural logarithm of public expenditure per
capita, and government expenditure as a percentage of GDP. Since the outcomes
have different scales, we treat them separately in our models.

```{r, cache=TRUE, echo = FALSE}
aux <- filter(dat, indepvar2 == "N")
binN <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
aux <- filter(dat, indepvar2=='K')
binK <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux <- filter(dat, indepvar2 == "logN")
binlogN <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
```

## Meta-Analysis
\label{sub:Meta-Analysis}

```{r, echo = FALSE, message = FALSE, warning = FALSE, cache=TRUE}
mod <- list()
# Pooling effects analysis -- ExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod[[1]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- ExpPC x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod[[2]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
# Pooling effects analysis -- logExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod[[3]] <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction = TRUE,
  sm="SMD"
  )

# Pooling effects analysis -- logExpPC x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod[[4]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- PCTGDP x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod[[5]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- PCTGDP x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod[[6]] <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction=TRUE,
  sm="SMD"
  )

# Pooling effects analysis -- PCTGDP x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod[[7]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Full model - Pooling effects analysis -- PCTGDP x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod[[8]] <- metagen(coef, SE, data = aux,
          studlab = paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm = "SMD")


# Full data - Pooling effects analysis -- ExpPC x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod[[9]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
```

We begin with the meta-analysis. We matched the house size variables with
our measures of government spending and created a theoretical $3 \times 3$
matrix. Out of the nine variable combinations, we found only seven the article
pool. Our sample does not contain any papers that analyse the relationships
between log lower chamber size and public expenditure per capita, or between
upper chamber size and the logarithm of public expenditure per capita. 

Figure \ref{fig:plots} shows the forest plots for our restricted sample, which
includes the `r dim(dat)[1]` main coefficients of the `r length(unique(dat$id))`
selected papers.\footnote{Please refer to Sections H and I in the Supplementary
Material for full results regarding both samples.} On the left side of the
plots are the names of the study authors and paper publication year. For
unpublished studies, we included the first year the paper was available online.
The bars in the middle show the reported effect sizes and the vertical lines
indicate their average, weighted by standard errors. The length of the lines
represent the precision of the estimates. The red line at the bottom of the
figures displays the overall effects plus their respective confidence
intervals.

The uppermost row shows the results for lower chamber size in our restricted
sample. In the first model, which correlates lower house and expenditure per
capita, we find a standardised mean difference (SMD) of 0.022 and a standard
error of 0.131 (figure 1.1, studies = `r mod[[1]]$k`, 95\% CI = [-0.256;
0.299], $p$-value = 0.87), so we cannot rule out that the effect is 
zero. Indeed, the effect of lower chamber size on the other two dependent
variables is also null in statistical terms. When we compare lower chamber size
with log expenditure per capita, the overall effect size is -0.031 and the
standard error is 0.049 (figure 1.2, studies = `r mod[[3]]$k`, 95\% CI =
[-0.188; 0.127], $p$-value = 0.58). The impact of larger lower houses on
government spending as a percentage of GDP  is also negligible (figure 1.3,
studies = `r mod[[5]]$k`, SMD = - 0.006, 95\% CI = [-0.0334; 0.021], $p$-value
= 0.563). The results are virtually identical when we estimate the
meta-analyses using our extended sample, and all three coefficients are
again statistically indistinguishable from zero. 

Next, we present the meta-analyses using the logarithm of lower house size as
an independent variable. The relationship between this variable and the log of
per capita expenditure is positive, but the coefficient is not significant
(figure 1.4, studies = `r mod[[4]]$k`, SMD = 0.078, SE = 0.109, 95\% CI =
[-0.225; 0.381], $p$-value = 0.515). The effect of log lower house size on
expenditure as a percentage of the GDP is negative, but it is again
non-statistically significant (figure 1.5, studies = `r mod[[6]]$k`, SMD = 
`r round(mod[[6]]$TE.random,3)`, SE = `r round(mod[[6]]$seTE.random,3)`, 95\% CI =
[`r round(mod[[6]]$lower.random,3)`; `r round(mod[[6]]$upper.random,3)`],
$p$-value = `r round(mod[[6]]$pval.random,3)`). Results in the full sample are
also null, and the coefficients for each dependent variable have the same sign
as the restricted sample -- positive and negative, respectively.

\begin{landscape}
\begin{figure}[!ht]
\centering
\caption{Forest plots of the relationship between legislature size and government spending (main sample)}
\vspace{0.3cm}
\includegraphics[width=25cm,height=17cm]{../graphs/graph1.pdf}
\label{fig:plots}
\end{figure}
\end{landscape}

The third set of models uses upper house size as the main independent variable.
We find a positive correlation between this variable and expenditure per capita
(figure 1.6, studies = `r mod[[2]]$k`, SMD = 3.658, SE = 4.299, 95\% CI =
[-6.255; 13.572], $p$-value = 0.419), and a negative relationship with
government spending as a percentage of GDP (figure 1.7, studies = 
`r mod[[7]]$k`, SMD = `r round(mod[[7]]$TE.random,3)`, SE = 
`r round(mod[[7]]$seTE.random,3)`, 95\% CI = [`r round(mod[[7]]$lower.random,3)`;
`r round(mod[[7]]$upper.random,3)`], $p$-value = 
`r round(mod[[7]]$pval.random,3)`), yet neither coefficient is statistically
significant. Results are the same in our extended sample.

Taken together, these results yield conservative interpretations. Besides all
average effect sizes not reaching conventional levels of statistical
significance, the studies are also notably heterogeneous. The $I^2$ statistic
quantifies the degree of heterogeneity among studies. @higgins2019cochrane
consider any $I^2$ value above 75\% to indicate high heterogeneity, and the
lowest $I^2$ we find in the restricted sample is `r round(mod[[2]]$I2*100,
2)`\% (for the subset of upper chamber size and per capita expenditure).
Additionally, all prediction intervals encompass zero. Therefore, we cannot
reject the null hypothesis that the effect size is zero in any variable
combination.

In a nutshell, we do not find evidence in favour of the "law of $1/n$".
One reason for this may be the identification strategy authors use in their
models. On the one hand, OLS and panel data models require too many controls to
make units comparable, and they are vulnerable to omitted variable bias or
post-treatment bias [@cinelli2020making; @pearl2015conditioning]. On the other
hand, estimation methods such as instrumental variables (IV) and regression
discontinuity designs (RDD) have become popular because of their high internal
validity [@angrist2008mostly]. Figure \ref{fig:plots2} shows the disaggregated
effects for two sets of models that employ causal estimation techniques. They
measure the impact of lower house size on expenditure per capita (left) and on
the natural logarithm of expenditure per capita (right).

\vspace{.5cm}

\begin{figure}[htb]
\begin{center}
\caption{Forest plots of the relationship between legislature size and government spending with regression method heterogeneity (main sample)}
\vspace{.3cm}
\includegraphics[width=1\linewidth, height=7.8cm]{../graphs/graph2.pdf}
\label{fig:plots2}
\end{center}
\end{figure}

Papers that employ instrumental variables and panel/fixed-effects models show
somewhat symmetrical distributions. Out of the five papers listed under IV, two
are positive, two are negative, and one is null. In the plot for panel data,
although more studies accumulate negative coefficients, the positive shifts are
more pronounced, so the overall effect is also null. In contrast, all papers
that use regression discontinuity designs show negative and statistically
significant results. Since only three papers in this model use
RDDs[^pettersson], we are cautious about predicting an overall negative
relationship, but they do indicate that better identification strategies yield
a zero-to-negative impact of legislature size on expenditure, in support of the
"reverse law of $1/n$".

[^pettersson]: @petterssonlidbom2012size also uses RDDs but the study is not
included in this model as it employs log lower chamber size as the independent
variable.

## Meta-Regressions
\label{sub:regressions}

In this section, we run a series of meta-regressions with six moderators to
account for the heterogeneity across the selected papers. The first variable
indicates whether the study uses lower chamber size, log lower chamber size, or
upper chamber size as a main explanatory variable. We include separate effect
sizes for upper and lower chamber sizes when papers analysed both. The second
variable shows the study publication year, which we included to capture
temporal variation in the study coefficients. We also add a dummy variable to
assess whether published articles report effect sizes that are higher or lower
than those from working papers. The fourth variable measures whether studies
focusing on non-majoritarian electoral systems report coefficients that are
smaller or larger than those from majoritarian countries. The fifth covariate
is a categorical variable indicating the statistical procedure used in the
original models (panel data, instrumental variables, OLS, or regression
discontinuity design). In our last variable, we separate coefficients produced
from samples of unicameral or bicameral systems, and code papers that analyse
multiple polities with different institutional designs as "mixed".

Table \ref{tab:regressions} presents the meta-regression results for our
restricted and extended samples. Each column represents one of the three
measures of public spending we discuss in this paper, and the last one uses all
coefficients. To reduce the risk of false positives in our analyses, we use
permutation tests to calculate significance levels for the meta-regressions
\citep{higgins2004controlling}. To interpret these results, the sign of
coefficients matters the most. These meta-regression coefficients can be viewed
as representing "the effect of the moderator on the $1/n$ effect". This means
positive coefficients predict a strengthening of the $1/n$ effect, and negative
ones predict it will get weaker under that moderator category, when compared to
its reference category. Since we aggregate different types of independent
variables under the same models, the size of the effects does not accurately
translate the scale of variations.

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', cache = TRUE}
res <- list()

# Aux fctns
strep <- function (x) {
  if(!is.na(x)) {
    return(ifelse(x<0.01, '***',ifelse(x<0.05,'**', ifelse(x<0.1,'*',''))))
  } else {
    return('')
  }
}

extract_coefs <- function(mod, modnam) {
  dfr <- data.frame(
     nams2 = row.names(mod[["beta"]]),
     est = mod[["beta"]],
     se = mod[["se"]],
     pval = mod[["pval"]],
     model = modnam
  )
  aux <- data.frame(nams = c("Intercept",
             "Indepvar: logN",
             "Indepvar: N",
             "Year",
             "Published",
             "Elecsys: Non-Majoritarian",
             "Method: Panel",
             "Method: IV",
             "Method: RDD",
             "Legislature: Mixed",
             "Legislature: Unicameral"), 
             nams2 = c("intrcpt", 
                       "indepvar2logN", 
                       "indepvar2N", 
                       "year", 
                       "publishedYes", 
                       "elecsys2Non-Maj", 
                       "methodPANEL", 
                       "methodIV", 
                       "methodRDD",
                       "instdesignMixed",
                       "instdesignUnicameral"))
  dfr <- left_join(aux, dfr) %>%
    mutate_if(is.numeric, list(~round(., digits = 4)))
  dfr$nams2 <- NULL
  return(dfr)
}

gcf <- function(mod, pos) {
  x <- mod$est[pos]
  y <- mod$pval[pos]
  if(!is.na(x)) {
    return(paste0(format(round(x, digits = 3), nsmall = 3), strep(y)))
  } else {
    return('')
  }
}
gcf2 <- function(mod, pos) {
  x <- mod$se[pos]
  if(!is.na(x)) {
    return(paste0('(', format(round(x, digits = 3), nsmall = 3), ')'))
  } else {
    return('')
  }
}

# Expenditure per capita - Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              sparse = TRUE,
              tdist = TRUE,
              subset = dat$depvar2=='ExpPC',
              slab = dat$authoryear)

res[[1]] <- extract_coefs(mod, "ExpPC")

# Expenditure per capita - Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = fulldat$depvar2=='ExpPC',
              slab = fulldat$authoryear)

res[[2]] <- extract_coefs(mod, "ExpPC - All coefs")

# Log of Expenditure per capita - Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = dat$depvar2=='logExpPC',
              slab = dat$authoryear)

res[[3]] <- extract_coefs(mod, "logExpPC")

# Log of Expenditure per capita - Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = fulldat$depvar2=='logExpPC',
              slab = fulldat$authoryear)

res[[4]] <- extract_coefs(mod, "logExpPC - All coefs")

## Expenditure as percentage GDP -- Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = dat$depvar2=='PCTGDP',
              slab = dat$authoryear)

res[[5]] <- extract_coefs(mod, "PCTGDP")

## Expenditure as percentage GDP -- Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
            subset = fulldat$depvar2=='PCTGDP',
            slab = fulldat$authoryear)

res[[6]] <- extract_coefs(mod, "PCTGDP - All coefs")

mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~depvar2+indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              slab = dat$authoryear)

res[[7]] <- extract_coefs(mod, "Full Model")

mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~depvar2+indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              slab = fulldat$authoryear)

res[[8]] <- extract_coefs(mod, "Full Model - All coefs")
```

\vspace{0.5cm}

```{=latex}
\begin{table}[htpb]
\caption{Meta-regression results\label{tab:regressions}}
\scriptsize
\centering
\begin{tabular}{lcccccccc}
\toprule
\midrule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Expenditure Per Capita} & \multicolumn{2}{c}{Log Expenditure Per Capita} & \multicolumn{2}{c}{Gov. Spending \% GDP} & \multicolumn{2}{c}{All Coefficients} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-9}
& Restricted & Extended & Restricted & Extended & Restricted & Extended & Restricted & Extended \\
\midrule
Log of Lower Chamber Size & 
`r gcf(res[[1]], 2)` & `r gcf(res[[2]], 2)` & 
`r gcf(res[[3]], 2)` & `r gcf(res[[4]], 2)` & 
`r gcf(res[[5]], 2)` & `r gcf(res[[6]], 2)` &
`r gcf(res[[7]], 2)` & `r gcf(res[[8]], 2)` \\
 & `r gcf2(res[[1]], 2)` & `r gcf2(res[[2]], 2)` & 
`r gcf2(res[[3]], 2)` & `r gcf2(res[[4]], 2)` & 
`r gcf2(res[[5]], 2)` & `r gcf2(res[[6]], 2)` & 
`r gcf2(res[[7]], 2)` & `r gcf2(res[[8]], 2)` \\
%
Lower Chamber Size &
`r gcf(res[[1]], 3)` & `r gcf(res[[2]], 3)` & 
`r gcf(res[[3]], 3)` & `r gcf(res[[4]], 3)` & 
`r gcf(res[[5]], 3)` & `r gcf(res[[6]], 3)` &
`r gcf(res[[7]], 3)` & `r gcf(res[[8]], 3)` \\
 & `r gcf2(res[[1]], 3)` & `r gcf2(res[[2]], 3)` & 
`r gcf2(res[[3]], 3)` & `r gcf2(res[[4]], 3)` & 
`r gcf2(res[[5]], 3)` & `r gcf2(res[[6]], 3)` & 
`r gcf2(res[[7]], 3)` & `r gcf2(res[[8]], 3)` \\
%
Year & 
`r gcf(res[[1]], 4)` & `r gcf(res[[2]], 4)` & 
`r gcf(res[[3]], 4)` & `r gcf(res[[4]], 4)` & 
`r gcf(res[[5]], 4)` & `r gcf(res[[6]], 4)` &
`r gcf(res[[7]], 4)` & `r gcf(res[[8]], 4)` \\
& `r gcf2(res[[1]], 4)` & `r gcf2(res[[2]], 4)` & 
`r gcf2(res[[3]], 4)` & `r gcf2(res[[4]], 4)` & 
`r gcf2(res[[5]], 4)` & `r gcf2(res[[6]], 4)` & 
`r gcf2(res[[7]], 4)` & `r gcf2(res[[8]], 4)` \\
%
Published: Yes & 
`r gcf(res[[1]], 5)` & `r gcf(res[[2]], 5)` & 
`r gcf(res[[3]], 5)` & `r gcf(res[[4]], 5)` & 
`r gcf(res[[5]], 5)` & `r gcf(res[[6]], 5)` &
`r gcf(res[[7]], 5)` & `r gcf(res[[8]], 5)` \\
& `r gcf2(res[[1]], 5)` & `r gcf2(res[[2]], 5)` & 
`r gcf2(res[[3]], 5)` & `r gcf2(res[[4]], 5)` & 
`r gcf2(res[[5]], 5)` & `r gcf2(res[[6]], 5)` & 
`r gcf2(res[[7]], 5)` & `r gcf2(res[[8]], 5)` \\
%
Non-Majoritarian & 
`r gcf(res[[1]], 6)` & `r gcf(res[[2]], 6)` & 
`r gcf(res[[3]], 6)` & `r gcf(res[[4]], 6)` & 
`r gcf(res[[5]], 6)` & `r gcf(res[[6]], 6)` &
`r gcf(res[[7]], 6)` & `r gcf(res[[8]], 6)` \\
& `r gcf2(res[[1]], 6)` & `r gcf2(res[[2]], 6)` & 
`r gcf2(res[[3]], 6)` & `r gcf2(res[[4]], 6)` & 
`r gcf2(res[[5]], 6)` & `r gcf2(res[[6]], 6)` & 
`r gcf2(res[[7]], 6)` & `r gcf2(res[[8]], 6)` \\
%
Method: Panel & 
`r gcf(res[[1]], 7)` & `r gcf(res[[2]], 7)` & 
`r gcf(res[[3]], 7)` & `r gcf(res[[4]], 7)` & 
`r gcf(res[[5]], 7)` & `r gcf(res[[6]], 7)` &
`r gcf(res[[7]], 7)` & `r gcf(res[[8]], 7)` \\
& `r gcf2(res[[1]], 7)` & `r gcf2(res[[2]], 7)` & 
`r gcf2(res[[3]], 7)` & `r gcf2(res[[4]], 7)` & 
`r gcf2(res[[5]], 7)` & `r gcf2(res[[6]], 7)` & 
`r gcf2(res[[7]], 7)` & `r gcf2(res[[8]], 7)` \\
%
Method: IV & 
`r gcf(res[[1]], 8)` & `r gcf(res[[2]], 8)` & 
`r gcf(res[[3]], 8)` & `r gcf(res[[4]], 8)` & 
`r gcf(res[[5]], 8)` & `r gcf(res[[6]], 8)` &
`r gcf(res[[7]], 8)` & `r gcf(res[[8]], 8)` \\
& `r gcf2(res[[1]], 8)` & `r gcf2(res[[2]], 8)` & 
`r gcf2(res[[3]], 8)` & `r gcf2(res[[4]], 8)` & 
`r gcf2(res[[5]], 8)` & `r gcf2(res[[6]], 8)` & 
`r gcf2(res[[7]], 8)` & `r gcf2(res[[8]], 8)` \\
%
Method: RDD &
`r gcf(res[[1]], 9)` & `r gcf(res[[2]], 9)` & 
`r gcf(res[[3]], 9)` & `r gcf(res[[4]], 9)` & 
`r gcf(res[[5]], 9)` & `r gcf(res[[6]], 9)` &
`r gcf(res[[7]], 9)` & `r gcf(res[[8]], 9)` \\
& `r gcf2(res[[1]], 9)` & `r gcf2(res[[2]], 9)` & 
`r gcf2(res[[3]], 9)` & `r gcf2(res[[4]], 9)` & 
`r gcf2(res[[5]], 9)` & `r gcf2(res[[6]], 9)` & 
`r gcf2(res[[7]], 9)` & `r gcf2(res[[8]], 9)` \\
% 
Inst. Design: Mixed & 
`r gcf(res[[1]], 10)` & `r gcf(res[[2]], 10)` & 
`r gcf(res[[3]], 10)` & `r gcf(res[[4]], 10)` & 
`r gcf(res[[5]], 10)` & `r gcf(res[[6]], 10)` &
`r gcf(res[[7]], 10)` & `r gcf(res[[8]], 10)` \\
& `r gcf2(res[[1]], 10)` & `r gcf2(res[[2]], 10)` & 
`r gcf2(res[[3]], 10)` & `r gcf2(res[[4]], 10)` & 
`r gcf2(res[[5]], 10)` & `r gcf2(res[[6]], 10)` & 
`r gcf2(res[[7]], 10)` & `r gcf2(res[[8]], 10)` \\
% 
Inst. Design: Unicameral & 
`r gcf(res[[1]], 11)` & `r gcf(res[[2]], 11)` & 
`r gcf(res[[3]], 11)` & `r gcf(res[[4]], 11)` & 
`r gcf(res[[5]], 11)` & `r gcf(res[[6]], 11)` &
`r gcf(res[[7]], 11)` & `r gcf(res[[8]], 11)` \\
& `r gcf2(res[[1]], 11)` & `r gcf2(res[[2]], 11)` & 
`r gcf2(res[[3]], 11)` & `r gcf2(res[[4]], 11)` & 
`r gcf2(res[[5]], 11)` & `r gcf2(res[[6]], 11)` & 
`r gcf2(res[[7]], 11)` & `r gcf2(res[[8]], 11)` \\
% 
Intercept & 
`r gcf(res[[1]], 1)` & `r gcf(res[[2]], 1)` & 
`r gcf(res[[3]], 1)` & `r gcf(res[[4]], 1)` & 
`r gcf(res[[5]], 1)` & `r gcf(res[[6]], 1)` &
`r gcf(res[[7]], 1)` & `r gcf(res[[8]], 1)` \\
& `r gcf2(res[[1]], 1)` & `r gcf2(res[[2]], 1)` & 
`r gcf2(res[[3]], 1)` & `r gcf2(res[[4]], 1)` & 
`r gcf2(res[[5]], 1)` & `r gcf2(res[[6]], 1)` & 
`r gcf2(res[[7]], 1)` & `r gcf2(res[[8]], 1)` \\
\bottomrule
\end{tabular}
\begin{minipage}{\textwidth}
\renewcommand{\footnoterule}{}
\footnotetext{\textbf{Note:} {The restricted and extended samples include `r length(dat$id)` and `r length(fulldat$id)` study coefficients, respectively. We report the results from the permutation tests. Reference categories: Independent Variable $=$ Upper House Size; Published $=$ No; Method $=$ OLS, Inst. Design $=$ Bicameral. Significance codes: *** $p < 0.01$; ** $p < 0.05$; * $p < 0.10$. Blank cells mean that there is no sufficient data to estimate the parameter.}}
\end{minipage}
\end{table}
```
\vspace{0.5cm}

The first two models show the results for public expenditure per capita. No
variable reaches conventional levels of statistical significance in the
restricted sample. In the extended sample, we find that models that use lower
chamber size as an independent variable have lower effects when compared to
upper chamber size. This suggests that an additional member in the lower house
has a smaller impact on public spending than a member in the upper house.
Moreover, the results for the extended sample point out that recent studies
find larger effects than older ones.

The third and fourth columns use the natural logarithm of expenditure per
capita as the dependent variable. Among the coefficients in the restricted
sample, those in published studies tend to be smaller than those in
working papers\footnote{We find no evidence of publication bias in our models.
The funnel plots for all estimations are available Sections H and I of the
Supplementary Material.}. Two other moderators are negatively associated with
the outcome in our larger coefficient pool. They both refer to estimation methods.
Studies that employ panel/fixed effects or regression discontinuity designs
(RDDs) have lower coefficients for log expenditure per capita if we take OLS as
the reference category.

Three estimates are statistically significant in the third set of
meta-regressions, which include public expenditure as a percentage of GDP as
the dependent variable. Both in our restricted and in our extended samples,
recent studies have smaller coefficients than older papers, which stands in
contrast with the first model. Institutional design also affects outcomes.
Papers that include mixed political systems report significantly lower
coefficients than those that analyse bicameral exclusively. Non-majoritarian
electoral systems have a small, positive effect in our extended sample model,
yet the coefficient is only significant at the 10\% level.

The last two columns report meta-regressions that aggregate all selected
studies. In the restricted sample of coefficients, unicameralism has a positive
effect. This result holds for the extended sample as well. When we regress all
`r dim(fulldat)[1]` coefficients, the effects of estimation methods become
stronger once again. Panel/fixed-effects models and regression discontinuity
designs both significantly decrease the $1/n$ effect. Instrumental variable
models follow along these lines. Non-majoritarian electoral systems are also
significantly associated with lower levels of public spending, which may be
justified since the "law of $1/n$" was conceived for majoritarian voting. These
latter results, however, do not replicate in the other sets of estimations.

The evidence seems to be sensitive to the methodological design. Our results
suggest that the same study samples may produce different outcomes depending on
the response variables scholars decide to analyse. The broadest aggregation
level presented the most insightful results in dialogue with the literature.
The additional legislator in non-majoritarian legislatures does not increase
expenditure as much as she would if the system were majoritarian. We are also
more likely to witness legislative expenditure growing along with the amount of
representatives in unicameral legislatures rather than in bicameral systems.
This indicates that while the "law of $1/n$" is not generalisable, its predicted
effects are stronger when the institutional features of a polity come closer to
its original theoretical framework.

# Discussion
\label{sec:discussion}

In this letter, we use meta-analytic methods to assess the generality of the
"law of $1/n$". Based on a sample of `r length(unique(dat$id))` publications,
our meta-analyses show that there is no strong evidence that an increase in the
number of legislators has a significant effect on public expenditures. The
meta-regressions indicate that study characteristics have a considerable
influence on reported results. Electoral system affects the relationship
between legislature size and public expenditure, but the results are not
replicable in all estimations. In our extended sample, we find that
unicameralism favours the $1/n$ effect. Publication year generates conflicting
findings in our models, but recent papers tend to present smaller coefficients
than older ones. The meta-regressions confirm that modern estimation methods
such as RDDs and panel/fixed-effects models decrease effects more frequently
than OLS regressions. In a nutshell, we only find moderate support for the "law
of $1/n$" in unicameral governments and in the upper house, mostly when authors
used OLS estimators.

While the vast literature covering the "law of $1/n$" builds important
empirical knowledge, we hypothesise that some of the null findings that we
present here are due to difficulties in testing important assumptions behind
the theory itself. For instance, the theory assumes three types of costs for
legislative public good provision, namely expenses for the constituency,
expenses outside the constituency, and externalities. The main issue in
assessing their actual impact is that externalities such as shifts in prices of
local firms, for example, are extremely hard to measure. Thus, it is very
difficult to properly translate the mechanism to empirical data, making it is
easy to accidentally distort results. Therefore, it should not come as a
surprise that slight differences in political features generate highly
heterogeneous results.

In this sense, the empirical cases in the literature may not always be the most
fortunate testing ground for the "law of $1/n$". While we believe that moving
beyond the majoritarian districts framework could produce valuable insights,
institutional features that are central to the theory cannot be overrun. For
example, proportional representation (PR) electoral systems allow candidates
whose constituents are spread across large territories to provide diffused
public goods and win elections. However, geographically-targeted service
provision is at the very core of the legislative behaviour that produces the
"law of $1/n$". Thus, scholars should consider the possible implications of
these micro-level dynamics when applying the "law of $1/n$" logic to different
settings. 

Another plausible reason why there is no clear-cut evidence in favour or
against the "law of $1/n$" may be that there are few incentives for the pure
accumulation of knowledge in the social sciences, at least when compared to the
benefits scholars may accrue when they challenge or add features to existing
theories [@geddes2003paradigms]. This leads to a reduced number of replication
studies and research syntheses in the field, although we have seen some
positive changes in this respect, such as EGAP's _Metaketa
Initiative_\footnote{See
\url{https://egap.org/our-work/the-metaketa-initiative} for further
information.}. Here we show that continuously producing and consuming
meta-analyses is a viable path towards knowledge-building in our discipline.
Although aggregating observational -- instead of experimental -- data can be
especially challenging, we believe that research synthesis methods play an
essential role in advancing our understanding of complex political phenomena.

Our analyses suggest other avenues for further research. First, our study
sample did not include articles that evaluate the association between the
natural logarithm of lower chamber size and public expenditure per capita, or
between upper house size and log expenditure per capita. New work on that area
might clarify some of the inconsistencies we find here. Second, despite the
inclusion of several moderators in our models, aggregate results still show
considerable heterogeneity. Domestic factors such as party dynamics or
gerrymandering [@lee2015supermajority; @mukherjee2003politicalparties;
@gilligan2006public] may prove useful in explaining those divergent results.
Third, authors should leverage natural and quasi-experiments to assess whether
the current results hold when systematically tested. Fortunately, this may also
be a trend under way, as all four studies using regression discontinuity
designs in our sample were published within less than 10 years prior to this
meta-analysis. These suggestions may help scholars to validate the robustness
of their findings and policy-makers to reach an optimal balance between sound
fiscal policy and the demands for increased political representation.

\setlength{\parindent}{0cm}
\setlength{\parskip}{5pt}

\nocite{baskaran2013coalition, bradbury2009spatially, drew2017price,
erler2007termlimits, fiorino2007legislature, hohmann2017effect,
kessler2014communication, lewis2019legislature, lledo2003electoral,
mukherjee2003politicalparties, petterssonlidbom2012size, schaltegger2009large,
stein1998institutional, mukherjee2003politicalparties, macdonald2008impact,
matsusaka2005endogeneity, ricciuti2004legislatures, coate2011government}

